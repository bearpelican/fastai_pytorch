{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_008 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rossmann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the feature-engineered filed train_clean and test_clean from the initial data, run nb009a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/rossmann/')\n",
    "train_df = pd.read_feather(PATH/'train_clean')\n",
    "test_df = pd.read_feather(PATH/'test_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = ['Store', 'DayOfWeek', 'Year', 'Month', 'Day', 'StateHoliday', 'CompetitionMonthsOpen',\n",
    "    'Promo2Weeks', 'StoreType', 'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear',\n",
    "    'State', 'Week', 'Events', 'Promo_fw', 'Promo_bw', 'StateHoliday_fw', 'StateHoliday_bw',\n",
    "    'SchoolHoliday_fw', 'SchoolHoliday_bw']\n",
    "\n",
    "cont_vars = ['CompetitionDistance', 'Max_TemperatureC', 'Mean_TemperatureC', 'Min_TemperatureC',\n",
    "   'Max_Humidity', 'Mean_Humidity', 'Min_Humidity', 'Max_Wind_SpeedKm_h', \n",
    "   'Mean_Wind_SpeedKm_h', 'CloudCover', 'trend', 'trend_DE',\n",
    "   'AfterStateHoliday', 'BeforeStateHoliday', 'Promo', 'SchoolHoliday']\n",
    "\n",
    "n = len(train_df); n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(range(n))[:2000]\n",
    "idx.sort()\n",
    "small_train_df = train_df.iloc[idx[:1000]]\n",
    "small_test_df = train_df.iloc[idx[1000:]]\n",
    "small_cont_vars = ['CompetitionDistance', 'Mean_Humidity']\n",
    "small_cat_vars =  ['Store', 'DayOfWeek', 'PromoInterval']\n",
    "small_train_df = small_train_df[small_cat_vars+small_cont_vars + ['Sales']]\n",
    "small_test_df = small_test_df[small_cat_vars+small_cont_vars + ['Sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TabularTransform():\n",
    "    cat_names:Collection[str]\n",
    "    cont_names:Collection[str]\n",
    "        \n",
    "    def __call__(self, df, test=False):\n",
    "        func = self.apply_test if test else self.apply_train\n",
    "        func(df)\n",
    "        \n",
    "    def apply_train(self, df): raise NotImplementedError\n",
    "    def apply_test(self, df):  self.apply_train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Categorify(TabularTransform):\n",
    "    \n",
    "    def apply_train(self, df):\n",
    "        self.categories = {}\n",
    "        for n in self.cat_names: \n",
    "            df[n] = df[n].astype('category').cat.as_ordered()\n",
    "            self.categories[n] = df[n].cat.categories\n",
    "    \n",
    "    def apply_test(self, df):\n",
    "        for n in self.cat_names:\n",
    "            df[n] = pd.Categorical(df[n], categories=self.categories[n], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorify = Categorify(small_cat_vars, small_cont_vars)\n",
    "categorify(small_train_df)\n",
    "categorify(small_test_df, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_df['PromoInterval'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test_df['Store'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FillNACont(TabularTransform):\n",
    "    fill_val:float=0.\n",
    "        \n",
    "    def apply_train(self, df):\n",
    "        for n in self.cont_names: df[n] = df[n].fillna(self.fill_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_df1 = small_train_df.copy()\n",
    "fillna = FillNACont(small_cat_vars, small_cont_vars)\n",
    "fillna(small_train_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(small_train_df['CompetitionDistance']).sum(), pd.isnull(small_train_df1['CompetitionDistance']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FillStrategy = IntEnum('FillStrategy', 'MEDIAN COMMON')\n",
    "\n",
    "@dataclass\n",
    "class FillMissing(TabularTransform):\n",
    "    fill_strategy:FillStrategy=FillStrategy.MEDIAN\n",
    "    add_col:bool=True\n",
    "        \n",
    "    def apply_train(self, df):\n",
    "        self.na_dict = {}\n",
    "        for name in self.cont_names:\n",
    "            if pd.isnull(df[name]).sum():\n",
    "                if self.add_col: \n",
    "                    df[name+'_na'] = pd.isnull(df[name])\n",
    "                    if name+'_na' not in self.cat_names: self.cat_names.append(name+'_na')\n",
    "                if self.fill_strategy == FillStrategy.MEDIAN: filler = df[name].median() \n",
    "                else: filler = df[name].dropna().value_counts().idxmax()\n",
    "                df[name] = df[name].fillna(filler)\n",
    "                self.na_dict[name] = filler\n",
    "            \n",
    "    def apply_test(self, df): \n",
    "        for name in self.cont_names:\n",
    "            if name in self.na_dict:\n",
    "                if self.add_col: \n",
    "                    df[name+'_na'] = pd.isnull(df[name])\n",
    "                    if name+'_na' not in self.cat_names: self.cat_names.append(name+'_na')\n",
    "                df[name] = df[name].fillna(self.na_dict[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_missing = FillMissing(small_cat_vars, small_cont_vars)\n",
    "fill_missing(small_train_df)\n",
    "fill_missing(small_test_df, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_df[small_train_df['CompetitionDistance_na'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test_df[small_test_df['CompetitionDistance_na'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype, is_categorical_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset():\n",
    "    def __init__(self, df, dep_var, cat_names=None, cont_names=None, stats=None, log_output=False):\n",
    "        if not is_numeric_dtype(df[dep_var]): df[dep_var] = df[dep_var].cat.codes\n",
    "        self.y = torch.tensor(df[dep_var].values)\n",
    "        if log_output: self.y = torch.log(self.y.float())\n",
    "        n = len(self.y)\n",
    "        if cat_names and len(cat_names) >= 1:\n",
    "            self.cats = np.stack([c.cat.codes.values for n,c in df[cat_names].items()], 1) + 1\n",
    "        else: self.cats = np.zeros((n,1))\n",
    "        self.cats = LongTensor(self.cats.astype(np.int64))\n",
    "        if cont_names and len(cont_names) >= 1:\n",
    "            self.conts = np.stack([c.astype('float32').values for n,c in df[cont_names].items()], 1)\n",
    "            means, stds = stats if stats is not None else (self.conts.mean(0), self.conts.std(0))\n",
    "            self.conts = (self.conts - means[None]) / stds[None]\n",
    "            self.stats = means,stds\n",
    "        else: \n",
    "            self.conts = np.zeros((n,1), dtype=np.float32)\n",
    "            self.stats = None\n",
    "        self.conts = FloatTensor(self.conts)\n",
    "    \n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self, idx): return ((self.cats[idx], self.conts[idx]), self.y[idx])\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframes(cls, train_df, test_df, dep_var, tfms=None, cat_names=None, cont_names=None, **kwargs):\n",
    "        if cat_names is None: cat_names = [n for n in train_df.columns if is_categorical_dtype(train_df[n])]\n",
    "        if cont_names is None: cont_names = [n for n in train_df.columns \n",
    "                                             if is_numeric_dtype_dtype(train_df[n]) and not n==dep_var]\n",
    "        if tfms is None: tfms = []\n",
    "        for tfm in tfms:\n",
    "            tfm = tfm(cat_names, cont_names)\n",
    "            tfm(train_df)\n",
    "            tfm(test_df, test=True)\n",
    "            cat_names, cont_names = tfm.cat_names, tfm.cont_names\n",
    "        train_ds = cls(train_df, dep_var, cat_names, cont_names, **kwargs)\n",
    "        return (train_ds, cls(test_df, dep_var, cat_names, cont_names, stats=train_ds.stats, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_feather(PATH/'train_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(range(n))[:2000]\n",
    "idx.sort()\n",
    "small_train_df = train_df.iloc[idx[:1000]]\n",
    "small_test_df = train_df.iloc[idx[1000:]]\n",
    "small_cont_vars = ['CompetitionDistance', 'Mean_Humidity']\n",
    "small_cat_vars =  ['Store', 'DayOfWeek', 'PromoInterval']\n",
    "small_train_df = small_train_df[small_cat_vars+small_cont_vars + ['Sales']]\n",
    "small_test_df = small_test_df[small_cat_vars+small_cont_vars + ['Sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var = 'Sales'\n",
    "tfms = [FillMissing, Categorify] #Fillmissing first so that the added columns are categorified\n",
    "train_ds, valid_ds = TabularDataset.from_dataframes(small_train_df, small_test_df, dep_var, tfms, cat_names=small_cat_vars, \n",
    "                                                    cont_names=small_cont_vars, log_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.stats, valid_ds.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var = 'Sales'\n",
    "train_df = pd.read_feather(PATH/'train_clean')\n",
    "train_df = train_df[cat_vars+cont_vars+[dep_var, 'Date']].copy()\n",
    "train_df = train_df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = int(len(train_df) * 0.1)\n",
    "train_df,valid_df = train_df[cut:], train_df[:cut]\n",
    "len(train_df),len(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [FillNACont, Categorify]\n",
    "train_ds, valid_ds = TabularDataset.from_dataframes(train_df, valid_df, dep_var, tfms, cat_names=cat_vars, \n",
    "                                                    cont_names=cont_vars, log_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch.create(train_ds, valid_ds, bs=64, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(data.train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0].size(), x[1].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_drop_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, drops, emb_drop=0., y_range=None, use_bn=True, \n",
    "                 is_reg=False, is_multi=False):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([get_embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(emb_drop)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeds)\n",
    "        self.n_emb,self.n_cont,self.y_range = n_emb,n_cont,y_range\n",
    "        layers = []\n",
    "        if is_reg: final_act = None if y_range is None else nn.Sigmoid()\n",
    "        else:      final_act = nn.LogSoftmax() if is_multi else nn.Sigmoid()\n",
    "        sizes = [n_emb + n_cont] + layers + [out_sz]\n",
    "        actns = [nn.ReLU(inplace=True)] * (len(sizes)-2) + [final_act]\n",
    "        for i,(n_in,n_out,dp,act) in enumerate(zip(sizes[:-1],sizes[1:],[0.]+drops,actns)):\n",
    "            layers += bn_drop_lin(n_in, n_out, bn=use_bn and i!=0, p=dp, actn=act)\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        if self.n_emb != 0:\n",
    "            x = [e(x_cat[:,i]) for i,e in enumerate(self.embeds)]\n",
    "            x = torch.cat(x, 1)\n",
    "            x = self.emb_drop(x)\n",
    "        if self.n_cont != 0:\n",
    "            x_cont = self.bn_cont(x_cont)\n",
    "            x = torch.cat([x, x_cont], 1) if self.n_emb != 0 else x_cont\n",
    "        x = self.layers(x)\n",
    "        if self.y_range is not None: x = (self.y_range[1] - self.y_range[0]) * x + self.y_range[0]\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_szs = [len(train_df[n].cat.categories)+1 for n in cat_vars]\n",
    "emb_szs = [(c, min(50, (c+1)//2)) for c in cat_szs]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_log_y = np.log(np.max(train_df['Sales']))\n",
    "y_range = torch.tensor([0, max_log_y*1.2], device=default_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabularModel(emb_szs, len(cont_vars), 1, [1000,500], [0.001,0.01], emb_drop=0.04, y_range=y_range, is_reg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_rmspe(pred, targ):\n",
    "    pred, targ =torch.exp(pred), torch.exp(targ)\n",
    "    pct_var = (targ - pred)/targ\n",
    "    return torch.sqrt((pct_var**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, model)\n",
    "learn.loss_fn = F.mse_loss\n",
    "learn.metrics = [exp_rmspe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(3, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
